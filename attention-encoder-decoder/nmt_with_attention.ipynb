{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T17:15:19.247483Z",
     "start_time": "2020-09-25T17:15:19.242601Z"
    },
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiwtNgENbx2g"
   },
   "source": [
    "This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation. This is an advanced example that assumes some knowledge of sequence to sequence models.\n",
    "\n",
    "After training the model in this notebook, you will be able to input a Spanish sentence, such as *\"¿todavia estan en casa?\"*, and return the English translation: *\"are you still at home?\"*\n",
    "\n",
    "The translation quality is reasonable for a toy example, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:\n",
    "\n",
    "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
    "\n",
    " \n",
    "<img src=\"images/spanish-english.png\" alt=\"spanish-english attention plot\" />\n",
    "\n",
    "Note: This example takes approximately 10 minutes to run on a single P100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:47:46.675802Z",
     "start_time": "2020-12-13T22:47:46.670916Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:28.187170Z",
     "start_time": "2020-12-13T22:13:28.053699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if using GPU:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TF version used:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "print('check if using GPU: ', tf.config.list_physical_devices('GPU'))\n",
    "print('TF version used: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "There are a variety of languages available, but we'll use the English-Spanish dataset. For convenience, we've hosted a copy of this dataset on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:31.011852Z",
     "start_time": "2020-12-13T22:13:31.005542Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# # Download the file\n",
    "# path_to_zip = tf.keras.utils.get_file(\n",
    "#     'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "#     extract=True, cache_subdir='/tf/notebooks/')\n",
    "\n",
    "# path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:36.343480Z",
     "start_time": "2020-12-13T22:13:36.341653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saved data to disk already (cell above)\n",
    "path_to_file = 'spanish-english/spanish-english-pairs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:37.370661Z",
     "start_time": "2020-12-13T22:13:37.365822Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)   # r\" \\1 \" means keep the first subgroup returned in the re library. In our\n",
    "                                         # case we only have 1 subgroup so wherever it finds what is in the parenthesis, \n",
    "                                         # it will put a space on both sides of it.\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "#   replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:38.281045Z",
     "start_time": "2020-12-13T22:13:38.276839Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "opI2GzOt479E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> may , i . borrow this book ? ? ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "en_sentence2 = u\"May, I .borrow this book???\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(en_sentence2))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:40.026122Z",
     "start_time": "2020-12-13T22:13:40.022145Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    # encode, read, strip spaces at beginning and end of the string, split at new line.\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    # each English and Spanish pair is seperated by a tab (\\t). This splits each pair \n",
    "    # into its respective language and preprocessed.\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "    # So far it looks like this\n",
    "#     [['<start> go . <end>', '<start> ve . <end>'],\n",
    "#  ['<start> go . <end>', '<start> vete . <end>'],\n",
    "#  ['<start> go . <end>', '<start> vaya . <end>'],\n",
    "#  ['<start> go . <end>', '<start> vayase . <end>'],\n",
    "#  ['<start> hi . <end>', '<start> hola . <end>'],\n",
    "#  ['<start> run ! <end>', '<start> corre ! <end>'],\n",
    "#  ['<start> run . <end>', '<start> corred . <end>'],\n",
    "#  ['<start> who ? <end>', '<start> ¿ quien ? <end>']...]\n",
    "\n",
    "\n",
    "    # Zipping allows us to separate each list in the list of lists.\n",
    "    # After zipping, we will return one object that only contains English \n",
    "    # and another object that only contains the Spanish translations.\n",
    "  word_pairs = zip(*word_pairs)\n",
    "\n",
    "  return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:45.857222Z",
     "start_time": "2020-12-13T22:13:40.532781Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cTbSbBz55QtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<start> a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities . some people try to reduce their carbon footprint because they are concerned about climate change . <end>', '<start> since there are usually multiple websites on any given topic , i usually just click the back button when i arrive on any webpage that has pop up advertising . i just go to the next page found by google and hope for something less irritating . <end>', '<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>')\n",
      "('<start> una huella de carbono es la cantidad de contaminacion de dioxido de carbono que producimos como producto de nuestras actividades . algunas personas intentan reducir su huella de carbono porque estan preocupados acerca del cambio climatico . <end>', '<start> como suele haber varias paginas web sobre cualquier tema , normalmente solo le doy al boton de retroceso cuando entro en una pagina web que tiene anuncios en ventanas emergentes . simplemente voy a la siguiente pagina encontrada por google y espero encontrar algo menos irritante . <end>', '<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>')\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-3:])\n",
    "print(sp[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:46.025630Z",
     "start_time": "2020-12-13T22:13:46.022149Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bIOn8RCNDJXG"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    \n",
    "    # You can see the breakdown of this function below. Basically, it turns tokens into\n",
    "    # integers. This particular notebook didn't use oov though.\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    # Turns each token to an integer.\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    # Pads at the end and according to the longest sequence in the list.\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:46.202241Z",
     "start_time": "2020-12-13T22:13:46.188885Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cTbSbBz55QtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<start> we ll do that later when we re not so busy . <end>', '<start> we ll furnish you with everything you need . <end>', '<start> we ll furnish you with everything you need . <end>')\n",
      "[[3, 1, 4, 11, 12, 13, 14, 1, 15, 16, 17, 18, 5, 6], [3, 1, 4, 7, 2, 8, 9, 2, 10, 5, 6], [3, 1, 4, 7, 2, 8, 9, 2, 10, 5, 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1,  4, 11, 12, 13, 14,  1, 15, 16, 17, 18,  5,  6],\n",
       "       [ 3,  1,  4,  7,  2,  8,  9,  2, 10,  5,  6,  0,  0,  0],\n",
       "       [ 3,  1,  4,  7,  2,  8,  9,  2, 10,  5,  6,  0,  0,  0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breakdown of the function above so you can see what it's doing.\n",
    "a = en[100_090:100_093]\n",
    "tokenize(a)\n",
    "\n",
    "print(a)\n",
    "_lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "\n",
    "_lang_tokenizer.fit_on_texts(a)\n",
    "\n",
    "_tensor = _lang_tokenizer.texts_to_sequences(a)\n",
    "\n",
    "print(_tensor)\n",
    "\n",
    "tf.keras.preprocessing.sequence.pad_sequences(_tensor, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:46.369026Z",
     "start_time": "2020-12-13T22:13:46.366257Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "\n",
    "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:48.768049Z",
     "start_time": "2020-12-13T22:13:46.526586Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cnxC7q-j3jFD"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30_000\n",
    "input_tensor, target_tensor, inp_lang_tokzer, targ_lang_tokzer = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:48.933416Z",
     "start_time": "2020-12-13T22:13:48.930847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1 1184  521   14  168    3    2    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1 9411   45 9412    3    2    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1   18 9413   74    3    2    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1   63 2490   34  182    3    2    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1   23 2175   10   39   98   87  314    3    2    0    0    0    0\n",
      "     0    0]]\n",
      "\n",
      "<keras_preprocessing.text.Tokenizer object at 0x7f2ec58b4dd8>\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor[-5:])\n",
    "print('')\n",
    "print(inp_lang_tokzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:49.099690Z",
     "start_time": "2020-12-13T22:13:49.094157Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4QILQkOs3jFG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:49.272146Z",
     "start_time": "2020-12-13T22:13:49.269532Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:49.436068Z",
     "start_time": "2020-12-13T22:13:49.432185Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VXukARTDd7MT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> ¿\n",
      "171 ----> deberia\n",
      "72 ----> ir\n",
      "5 ----> ?\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "123 ----> should\n",
      "4 ----> i\n",
      "36 ----> go\n",
      "7 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang_tokzer, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang_tokzer, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:50.013684Z",
     "start_time": "2020-12-13T22:13:49.609690Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "# FYI: You should not use the shuffle buffer size the way this author did. If you\n",
    "# had a lot of data it would be way too big of a shuffle buffer.\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang_tokzer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokzer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:50.228417Z",
     "start_time": "2020-12-13T22:13:50.180240Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of input tensor (Spanish):  16\n",
      "Max length of label tensor (English):  11\n"
     ]
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "\n",
    "print('Max length of input tensor (Spanish): ', example_input_batch.shape[1])\n",
    "print('Max length of label tensor (English): ', example_target_batch.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "<span class=\"girk\"> This highlighted part is written by me. The writing below is a confusing to figure out and I don't think the picture truly represents this implementation. What you need to know is that the output of the encoder is really all the hiddens states and also the last hidden state.</span>\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "<img src=\"images/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "<img src=\"images/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"images/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output (all hidden states; hidden state for each timestep)\n",
    "* H = hidden state (last hidden state)\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))` <span class=\"girk\">My own words, creates a scalar for each timestep.</span>\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis. <span class=\"girk\">In my own words, apply softmax to each timestep to get one attention weight per timestep. This is why you apply it to axis=1 (the timestep axis). When you do the softmax, you will have a weight for each input in the max_input_seq and doing the softmax will make the sum of all the weights = 1 which means that most inputs will probably be very low, maybe close to 0.</span>\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.  <span class=\"girk\">In my words, this will multiply the scalar attention weight and broadcast it (multiply it by every element in the hidden state of the timestep). Since most attention weights will probably be be super low, the hidden states of the corresponding timesteps will also become super low. Then it will sum along the timestep axis so you're left with the number of hidden state units.For example, if the hidden state is 1024 at each timestep and there is a max length of 16 words then the nultiplication of this attention broadcasted multiplication will still be 16, 1024. Then the sum occurs along the timestep (sum of the columns, aka timesteps, leaving the shape of (batch_size, hidden_state_units). Just look at the code in the function to understand it if this was confusing, it will become more clear.</span>\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:50.443294Z",
     "start_time": "2020-12-13T22:13:50.436361Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True, # returns all hidden states (1 for each timestep)\n",
    "                    return_state=True,  # returns the last hidden state of the encoder. \n",
    "                    # We want this because we'll feed it as the hidden state for the decoder's first timestep.\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    _all_hidden_states, _last_hidden_state = self.gru(x, initial_state = hidden)\n",
    "    return _all_hidden_states, _last_hidden_state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:52.458898Z",
     "start_time": "2020-12-13T22:13:50.619950Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape - all hidden states: (batch size, sequence length, hidden state units) (64, 16, 1024)\n",
      "Encoder Hidden state shape - overwritten hidden state: (batch size, hidden state units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "# Initialize by feeding all zero hidden state into first timestep.\n",
    "sample_hidden = encoder.initialize_hidden_state() \n",
    "\n",
    "# This will overwrite the initialized (all zero) hidden state from the first step with a new \n",
    "# hidden state to be passed to the next timestep.\n",
    "sample_all_hidden_states, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape - all hidden states: (batch size, sequence length, hidden state units) {}'.format(sample_all_hidden_states.shape))\n",
    "print ('Encoder Hidden state shape - overwritten hidden state: (batch size, hidden state units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:52.665545Z",
     "start_time": "2020-12-13T22:13:52.658704Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # My own words\n",
    "    # Query: Last hidden state of the encoder or decoder (batch_size, hidden units)\n",
    "    # Values: All the hidden states of the encoder (batch_size, max_len_input_timesteps, hidden state units)\n",
    "    \n",
    "    # Add a timestep to the query so we can add it to the 'Values' (all hidden states of encoder).\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    \n",
    "    ## Calculate the score.\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V (a 1 neuron linear Dense layer)\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, hidden units)\n",
    "    # My own words, hidden state units --> 1 (scalar)\n",
    "    \n",
    "    # Brokedown the score into 2 steps to make is easier to follow.\n",
    "    # 1. Put all hidden states encoder output and last hidden state through their own\n",
    "    # linear Denser layer and add them together. \n",
    "    # The hidden state, i.e. 1024 units, will be added to each\n",
    "    # timestep's hidden state which also has same number of hidden units, i.e. 1024. So, the resulting shape\n",
    "    # at each timestep remains, i.e. 1024 units.\n",
    "    # FYI: the all hidden states outputs actually also includes the last hidden state.\n",
    "    # So yes, the last hidden state output is adding to itself in the all hidden states encoder output.\n",
    "    # Then then go through a tanh so the values will be between [-1, 1]\n",
    "    addition_broadcast_last_hidden_to_all_hidden_states = tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values))\n",
    "    # 2.Turn the hidden state into a scalar. \n",
    "    # The shape of the tensor before applying self.V (Dense layer with 1 output) \n",
    "    # is (batch_size, max_input_seq_length, units)\n",
    "    # So, the final shape is (batch_size, max_input_seq_length, 1)\n",
    "    score = self.V(addition_broadcast_last_hidden_to_all_hidden_states) \n",
    "    \n",
    "\n",
    "    ## Calculate attention weights.\n",
    "    # _attention_weights shape == (batch_size, max_length, 1)\n",
    "    # Doing this along the timestep axis makes it so that adding each timestep sequence of the batch\n",
    "    # together will be equal to 1 (I know this is true because I tried it out to make sure). \n",
    "    # This helsp the network know which timesteps, or words, to focus \n",
    "    # on because the word, timestep, from the encoder to focus on will be have higher value while \n",
    "    # the other words, timesteps, will be closer to 0 (the sum will be 1 though). \n",
    "    # The softmax is not applied to each scalar individually. That wouldn't make any sense.\n",
    "    ## UNDERSTANDING APPLYING OPERATIONS TO AN AXIS!!!\n",
    "    # Axis for numpy and TF is not like Pandas. Simple way to figure out what operations are being applied\n",
    "    # to the axis is by doing addition on an axis. The axis in the argument will disappear in the output. \n",
    "    # For example, if you have a 2-d matrix (10, 5) and so tf.reduce_sum(axis=0) then the result is (5,) and the \n",
    "    # sum was along the columns. If you have a 3-d image (224, 224, 3) and do sum(axis=2) then the output is (224, 224) \n",
    "    # and the sum of all 3 channels at each pixel location in 2d space.\n",
    "    _attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    \n",
    "    ## Calculate context vector. \n",
    "    # 'Values' (all hidden states encoder output has shape (batch size, max_seq_length, hidden state units)).\n",
    "    # _attention_weights shape == (batch_size, max_seq_length, 1)\n",
    "    # There will be one scalar attention weight for each timestep in it's respective batch. \n",
    "    # This scalar will be broadcasted and multiplied on each hidden unit of that timestep. \n",
    "    # This means that words, timesteps, with high attention will be closer to 1 while\n",
    "    # words that should not be focused on will be closer to 0. Doing the\n",
    "    # broadcast multiplication will make the timesteps hidden units to be ignored also closer \n",
    "    # to 0 while the word to focus on will keep some of it's hidden state values because the attention\n",
    "    # weight will be higher (just remember though, the sum of all the attention weights for each batch will be 1).\n",
    "    _context_vector = _attention_weights * values\n",
    "    # context_vector shape after the broadcasted multiplication (batch_size, max_seq_length, hidden_size)\n",
    "    # Next step is to sum. Since we are summing on axis 1, that axis will disappear from the resulting matrix.\n",
    "    # The final shape of the _context_vector will be (batch_size, hidden_unit). So, each hidden unit had all its\n",
    "    # timesteps added together.\n",
    "    _context_vector = tf.reduce_sum(_context_vector, axis=1)\n",
    "\n",
    "    return _context_vector, _attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:52.867962Z",
     "start_time": "2020-12-13T22:13:52.866107Z"
    }
   },
   "outputs": [],
   "source": [
    "# attention_layer = BahdanauAttention(10)\n",
    "# context_vectors, attention_weights = attention_layer(sample_hidden, sample_all_hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:53.315017Z",
     "start_time": "2020-12-13T22:13:53.081971Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "k534zTHiDjQU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "context_vectors, attention_weights = attention_layer(sample_hidden, sample_all_hidden_states)\n",
    "\n",
    "print(\"Context vectors shape: (batch size, units) {}\".format(context_vectors.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:53.516532Z",
     "start_time": "2020-12-13T22:13:53.509430Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "#                                    return_sequences=True,  # Return all hidden states.\n",
    "                                   # We don't need this for the decoder because we are just predicting.\n",
    "#                                    return_state=True,  # Return last hidden state.\n",
    "                                   # We don't need this either for the decoder becuase the output is already\n",
    "                                   # a hidden state.\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    \n",
    "    # There is no softmax used because the loss in later cell below has the 'from_logits' argument set to True.\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size) \n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, _last_hidden_state, _all_hidden_states_enc_output):\n",
    "    # _all_hidden_states_enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    _context_vector, attention_weights = self.attention(_last_hidden_state, _all_hidden_states_enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_units)\n",
    "    # _context_vector shape (batch_size, hidden_units)\n",
    "    # My own words, you can think of the concat as putting 2 legos next to each other; NOT stacking them.\n",
    "    x = tf.concat([tf.expand_dims(_context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU.\n",
    "    # The output is only 1 hidden state because we passed in an input with \n",
    "    # only 1 timestep.\n",
    "    # _hidden_state shape (batch_size, hidden_units).\n",
    "    _hidden_state = self.gru(x)\n",
    "\n",
    "    # The hidden state gets passed to fully conected layer which has the\n",
    "    # same amount of neurons as the label vocab size.\n",
    "    # output shape == (batch_size, vocab size)\n",
    "    # There is no softmax used because the loss in a later cell below has \n",
    "    # the 'from_logits' argument set to True.\n",
    "    _word_prediction = self.fc(_hidden_state)  \n",
    "\n",
    "    return _word_prediction, _hidden_state, attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:53.741241Z",
     "start_time": "2020-12-13T22:13:53.708127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "P5UY8wko3jFp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "_word_batch_predictions, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_all_hidden_states)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(_word_batch_predictions.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:53.965522Z",
     "start_time": "2020-12-13T22:13:53.961370Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # I coudln't really figure out how this works. I kinda get it but not totally.\n",
    "    # The preds is a prediction at each timestep and the index with the highest value\n",
    "    # will map to the predicted word. There is no softmax used because the loss object\n",
    "    # has the 'from_logits' argument set to True.\n",
    "\n",
    "    # Turns all padded zeros into False and everything else into True.\n",
    "    # Real means the target label and it has shape (batch_size, max_targ_seq_length)\n",
    "  mask = tf.math.not_equal(real, 0)\n",
    "    \n",
    "    # The loss object is a SparseCategoricalCrossentropy so the target will\n",
    "    # just be an index. The predictions however in this code will not be. \n",
    "    # The predictions will be shape (batch_size, label_vocab_size)\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Looks like this mask will make the padded predictions into zero...IT.\n",
    "    # I guess the shape of the loss is (batch_size, label_vocab_size)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:56.322730Z",
     "start_time": "2020-12-13T22:13:56.317380Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The *decoder hidden state* is retained because it will be used in the next timestep for determining self attention; what words from the encoder input that the decoder input at that timestep should focus on.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:13:58.508685Z",
     "start_time": "2020-12-13T22:13:58.501927Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "# @tf.function will created a computational graph to make things faster (the first epoch \n",
    "# is longer to build the graph).\n",
    "# Since eager mode is always on in TF2, you need to comment out @tf.function\n",
    "# if you need to debug because you can't do that when a computational graph is made...IT \n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    all_enc_hidden_states_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    # Passing the last hidden state from the encoder to the first timestep of the decoder.\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # Starting the decoder with the '<start>' token index; a index number.\n",
    "    # All instances in the batch get the same index number to start decodeing to it is\n",
    "    # multiplied (broadcasted) by the batch size.\n",
    "    dec_input = tf.expand_dims([targ_lang_tokzer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    # Iterate through the max_seq_length of the target. In our case the input max seq length was 16\n",
    "    # and the target max_seq_length is 11. So, we are interating through 11 timesteps right now.\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing all_enc_hidden_states_output to the decoder and also the last hidden state of the encoder\n",
    "      # for the first step of this loop and then overwriting it.\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, all_enc_hidden_states_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing.\n",
    "    # Making the next decoder input be the label instead of the prediction.\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:15.011610Z",
     "start_time": "2020-12-13T22:13:58.909875Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ddefjBMa3jF0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6385\n",
      "Epoch 1 Batch 100 Loss 1.9920\n",
      "Epoch 1 Batch 200 Loss 1.9703\n",
      "Epoch 1 Batch 300 Loss 1.7427\n",
      "Epoch 1 Loss 2.0496\n",
      "Time taken for 1 epoch 32.93681263923645 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.6680\n",
      "Epoch 2 Batch 100 Loss 1.5478\n",
      "Epoch 2 Batch 200 Loss 1.3772\n",
      "Epoch 2 Batch 300 Loss 1.2324\n",
      "Epoch 2 Loss 1.4344\n",
      "Time taken for 1 epoch 24.940255403518677 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1873\n",
      "Epoch 3 Batch 100 Loss 1.2138\n",
      "Epoch 3 Batch 200 Loss 1.0442\n",
      "Epoch 3 Batch 300 Loss 0.8297\n",
      "Epoch 3 Loss 1.0311\n",
      "Time taken for 1 epoch 24.584212064743042 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8029\n",
      "Epoch 4 Batch 100 Loss 0.7249\n",
      "Epoch 4 Batch 200 Loss 0.7120\n",
      "Epoch 4 Batch 300 Loss 0.6940\n",
      "Epoch 4 Loss 0.7141\n",
      "Time taken for 1 epoch 24.883034706115723 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4726\n",
      "Epoch 5 Batch 100 Loss 0.4755\n",
      "Epoch 5 Batch 200 Loss 0.6766\n",
      "Epoch 5 Batch 300 Loss 0.4716\n",
      "Epoch 5 Loss 0.4955\n",
      "Time taken for 1 epoch 24.73435950279236 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4092\n",
      "Epoch 6 Batch 100 Loss 0.3524\n",
      "Epoch 6 Batch 200 Loss 0.3334\n",
      "Epoch 6 Batch 300 Loss 0.3355\n",
      "Epoch 6 Loss 0.3480\n",
      "Time taken for 1 epoch 24.901912212371826 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1786\n",
      "Epoch 7 Batch 100 Loss 0.2028\n",
      "Epoch 7 Batch 200 Loss 0.1764\n",
      "Epoch 7 Batch 300 Loss 0.1837\n",
      "Epoch 7 Loss 0.2496\n",
      "Time taken for 1 epoch 24.679479598999023 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1507\n",
      "Epoch 8 Batch 100 Loss 0.1817\n",
      "Epoch 8 Batch 200 Loss 0.2113\n",
      "Epoch 8 Batch 300 Loss 0.1771\n",
      "Epoch 8 Loss 0.1849\n",
      "Time taken for 1 epoch 24.89909291267395 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0876\n",
      "Epoch 9 Batch 100 Loss 0.1227\n",
      "Epoch 9 Batch 200 Loss 0.1265\n",
      "Epoch 9 Batch 300 Loss 0.1445\n",
      "Epoch 9 Loss 0.1419\n",
      "Time taken for 1 epoch 24.657592296600342 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0967\n",
      "Epoch 10 Batch 100 Loss 0.0832\n",
      "Epoch 10 Batch 200 Loss 0.1211\n",
      "Epoch 10 Batch 300 Loss 0.1364\n",
      "Epoch 10 Loss 0.1158\n",
      "Time taken for 1 epoch 24.87581467628479 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "    # Initialize the first time step by passing a initialized (all-zero)\n",
    "    # hidden state into the first encoder timestep.\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output (all hidden states).\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:15.235970Z",
     "start_time": "2020-12-13T22:18:15.228210Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  _attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang_tokzer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  _prediction = ''\n",
    "\n",
    "    # Initialize a hidden state (all zeros) to be fed into the first timestep.\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_output_all_hidden_states, enc_last_hidden_state = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_last_hidden_state\n",
    "  dec_input = tf.expand_dims([targ_lang_tokzer.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    # For each timestep in the decoder, you get back _attention_weights which is\n",
    "    # the length of the max_input_length. So, for each decoder prediction \n",
    "    # (which is 1 at a time) you're getting back the attention weights which would tell \n",
    "    # you which input words were focused on for that particular decoder prediction.\n",
    "    # Attention weights shape (input_max_length_seq, 1)\n",
    "    predictions, dec_hidden, _attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_output_all_hidden_states)\n",
    "\n",
    "    # storing the attention weights to plot later on.\n",
    "    # The plot shape returned by this function is \n",
    "    # (11, 16) == (max_label_seq_english, max_input_seq_spanish)\n",
    "    _attention_weights = tf.reshape(_attention_weights, (-1, ))\n",
    "    _attention_plot[t] = _attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    \n",
    "    # This is just making the predicted translation into one sequence.\n",
    "    _prediction += targ_lang_tokzer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang_tokzer.index_word[predicted_id] == '<end>':\n",
    "      return _prediction, sentence, _attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return _prediction, sentence, _attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:15.454034Z",
     "start_time": "2020-12-13T22:18:15.449538Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:15.670662Z",
     "start_time": "2020-12-13T22:18:15.666894Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "#   attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:16.058102Z",
     "start_time": "2020-12-13T22:18:15.903418Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UJpT9D5_OgP6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2ec5a5ef28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\">Understanding of the attention matrix: you can think of it as the input word gets fed in, it gets provided with extra information on what context (context vector) to consider in order to predict the next word. The context vector was created from calculations which were primarily determined from the attention weights because the attention weights are a softmax that sum to 1. The important word will be closer to 1 and other words closer to 0. The attention weights multiply everything and pretty much wipe out the encoding of the hidden states, \"values\", which should be ignored while retaining the word to focus on because the attention weight it gets multiplied will be closer to 1. This is why you can use the attention weights to plot which word was focused on when the model decided which word to predict.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:16.522533Z",
     "start_time": "2020-12-13T22:18:16.281200Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is what the plot looks like with the full attention weights matrix\n",
    "# which is shape (11, 16) == (max_label_seq_leng, max_input_seq_length)\n",
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:16.743325Z",
     "start_time": "2020-12-13T22:18:16.739701Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is what the plot looks like with the full attention weights matrix\n",
    "# which is shape (11, 16) == (max_label_seq_leng, max_input_seq_length)\n",
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:18:17.171719Z",
     "start_time": "2020-12-13T22:18:16.959322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is what the plot looks like with the full attention weights matrix\n",
    "# which is shape (11, 16) == (max_label_seq_leng, max_input_seq_length)\n",
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:45:25.139039Z",
     "start_time": "2020-12-13T22:45:24.903042Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zSx2iM36EZQZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:45:27.704177Z",
     "start_time": "2020-12-13T22:45:27.473246Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "A3LLCx3ZE0Ls"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:45:30.267479Z",
     "start_time": "2020-12-13T22:45:30.064160Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DUQVLVqUE1YW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wrong translation\n",
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T22:47:56.615356Z",
     "start_time": "2020-12-13T22:47:56.514690Z"
    }
   },
   "outputs": [],
   "source": [
    "# # remove checkpoints dir\n",
    "# rmtree('training_checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTe5P5ioMJwN"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "* [Download a different dataset](http://www.manythings.org/anki/) to experiment with translations, for example, English to German, or English to French.\n",
    "* Experiment with training on a larger dataset, or using more epochs\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
